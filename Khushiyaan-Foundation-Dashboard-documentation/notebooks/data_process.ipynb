{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5aa6da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "425f84c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dadar (11, 60)\n",
      "Cuff Parade (5, 16)\n",
      "Chimbai Beach, Bandra (5, 16)\n",
      "Worli Fort, Worli (5, 18)\n",
      "Madh, Malad (5, 16)\n",
      "Erangal, Malad (5, 16)\n",
      "Gorai, Bhayander (4, 16)\n",
      "Prabhadevi Beach (8, 16)\n",
      "Silver Beach (4, 15)\n",
      "Juhu Koliwada, Juhu (10, 16)\n",
      "Sheet1 (8, 3)\n"
     ]
    }
   ],
   "source": [
    "all_sheets = pd.read_excel(\"../Final Dashboard Data- 17-25 (1).xlsx\", sheet_name=None)\n",
    "\n",
    "for name, df in all_sheets.items():\n",
    "    print(name, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "26ecd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_period_year(series):\n",
    "    cleaned = (\n",
    "        series.astype(str)\n",
    "              .str.strip()                               # strip outer spaces\n",
    "              .str.replace(r\"\\s*-\\s*\", \"-\", regex=True)  # normalize spaces around '-'\n",
    "    )\n",
    "\n",
    "    # Normalize `(Legrand)` suffix\n",
    "    cleaned = cleaned.str.replace(r\"\\(\\s*legrand\\s*\\)\", \"(Legrand)\", \n",
    "                                  flags=re.IGNORECASE, regex=True)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def clean_columns(df):\n",
    "    rename_map = {}\n",
    "    for col in df.columns:\n",
    "        new_col = col\n",
    "\n",
    "        # Drop trailing \"participated\"\n",
    "        new_col = re.sub(r\"\\s+participated$\", \"\", new_col, flags=re.IGNORECASE)\n",
    "\n",
    "        # Fix typo \"LDTP\" -> \"LDP\"\n",
    "        new_col = new_col.replace(\"LDTP\", \"LDP\")\n",
    "\n",
    "        rename_map[col] = new_col\n",
    "    \n",
    "    return df.rename(columns=rename_map)\n",
    "\n",
    "def process_df_with_combined_headers(df, location_name):\n",
    "    \"\"\"\n",
    "    Process a dataframe with multi-level headers by combining column names with first row values.\n",
    "    Creates column names like 'Beach Clean Up_Number of Beach Clean Ups'\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "\n",
    "    # Remove completely empty rows\n",
    "    df = df.dropna(how='all').reset_index(drop=True)\n",
    "    \n",
    "    # Find the first row that has at least one non-null value\n",
    "    first_valid_idx = df.first_valid_index()\n",
    "\n",
    "    # Use that row as header\n",
    "    condition=False\n",
    "    if all(str(col).startswith(\"Unnamed\") for col in df.columns):\n",
    "        df.columns = df.iloc[first_valid_idx]\n",
    "        df = df.iloc[first_valid_idx+1:].reset_index(drop=True)\n",
    "        condition=True\n",
    "    else:\n",
    "        df = df.iloc[first_valid_idx:].reset_index(drop=True)\n",
    "\n",
    "    if condition:\n",
    "        main_headers=df.iloc[0].fillna('')\n",
    "    else:\n",
    "        # Get the main category headers (first row with data)\n",
    "        main_headers = df.iloc[first_valid_idx].fillna('')\n",
    "\n",
    "    # Fix column names by forward filling\n",
    "    new_cols = []\n",
    "    last_valid = None\n",
    "    for col in df.columns:\n",
    "        if (\"Unnamed\" in str(col)) or (str(col)=='nan'):\n",
    "            new_cols.append(last_valid)   # reuse last valid name\n",
    "        else:\n",
    "            new_cols.append(col)          # set new name\n",
    "            last_valid = col              # update last valid\n",
    "\n",
    "    df.columns = new_cols\n",
    "\n",
    "    df = df.dropna(how=\"all\").reset_index(drop=True)\n",
    "    \n",
    "    new_columns = [str(i) + \"_\" + str(j) for i, j in zip(df.columns , main_headers)]\n",
    "    df.columns = new_columns\n",
    "    df = df.iloc[1:, :].reset_index(drop=True)\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Remove completely empty columns\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Add location column\n",
    "    df['location'] = location_name\n",
    "    \n",
    "    # Remove rows containing 'total' (case-insensitive)\n",
    "    if len(df) > 0:\n",
    "        mask = df.astype(str).apply(lambda x: x.str.contains(\"total\", case=False, na=False)).any(axis=1)\n",
    "        df = df[~mask]\n",
    "    \n",
    "    # # # Remove rows that look like header repetitions\n",
    "    # # if len(data_df) > 0:\n",
    "    # #     # Check if any row has too many values that match column names\n",
    "    # #     header_mask = pd.Series(False, index=data_df.index)\n",
    "    # #     for idx, row in data_df.iterrows():\n",
    "    # #         row_values = set(str(val).strip().lower() for val in row.values if pd.notna(val) and str(val).strip())\n",
    "    # #         col_names = set(str(col).strip().lower() for col in data_df.columns)\n",
    "            \n",
    "    # #         # If more than 30% of non-null values match column names, it's likely a header row\n",
    "    # #         if len(row_values) > 0:\n",
    "    # #             matches = len(row_values.intersection(col_names))\n",
    "    # #             if matches / len(row_values) > 0.3:\n",
    "    # #                 header_mask[idx] = True\n",
    "        \n",
    "    #     data_df = data_df[~header_mask]\n",
    "    \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "9f5c550b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beach Name_Erangal, Malad</th>\n",
       "      <th>Beach Clean Up_Number of Beach Clean Ups</th>\n",
       "      <th>Beach Clean Up_Total Number of Participants</th>\n",
       "      <th>Beach Clean Up_Number of Beach Warrior Volunteers</th>\n",
       "      <th>Beach Clean Up_Number of Student Participants</th>\n",
       "      <th>Beach Clean Up_Number of Community Participants</th>\n",
       "      <th>Beach Clean Up_Number of RWA Participants</th>\n",
       "      <th>Beach Clean Up_Number of Government Representatives</th>\n",
       "      <th>Beach Clean Up_Number Local group volunteers</th>\n",
       "      <th>Beach Clean Up_Number of Academic Institutions</th>\n",
       "      <th>Beach Clean Up_Number of Residential Societies</th>\n",
       "      <th>Waste Management_Quantity of Marine Debris Collected (Kgs)</th>\n",
       "      <th>Waste Management_Quantity of Plastic (KGS)- Mix Plastic (Polythene, MLP, PVC, LDP)</th>\n",
       "      <th>Waste Management_Quantity of Cloth (KGS)</th>\n",
       "      <th>Waste Management_Quantity of Wood, Shoes, Bags and other materials (KGS)</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18-19</td>\n",
       "      <td>26</td>\n",
       "      <td>3569</td>\n",
       "      <td>95</td>\n",
       "      <td>2919</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>120</td>\n",
       "      <td>299</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6552</td>\n",
       "      <td>4258.8</td>\n",
       "      <td>982.8</td>\n",
       "      <td>1310.4</td>\n",
       "      <td>Erangal, Malad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19-20</td>\n",
       "      <td>52</td>\n",
       "      <td>4519</td>\n",
       "      <td>180</td>\n",
       "      <td>3291</td>\n",
       "      <td>153</td>\n",
       "      <td>162</td>\n",
       "      <td>260</td>\n",
       "      <td>473</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14940</td>\n",
       "      <td>9711</td>\n",
       "      <td>2241</td>\n",
       "      <td>2988</td>\n",
       "      <td>Erangal, Malad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Beach Name_Erangal, Malad Beach Clean Up_Number of Beach Clean Ups  \\\n",
       "0                     18-19                                       26   \n",
       "1                     19-20                                       52   \n",
       "\n",
       "  Beach Clean Up_Total Number of Participants  \\\n",
       "0                                        3569   \n",
       "1                                        4519   \n",
       "\n",
       "  Beach Clean Up_Number of Beach Warrior Volunteers  \\\n",
       "0                                                95   \n",
       "1                                               180   \n",
       "\n",
       "  Beach Clean Up_Number of Student Participants   \\\n",
       "0                                           2919   \n",
       "1                                           3291   \n",
       "\n",
       "  Beach Clean Up_Number of Community Participants  \\\n",
       "0                                              64   \n",
       "1                                             153   \n",
       "\n",
       "  Beach Clean Up_Number of RWA Participants  \\\n",
       "0                                        72   \n",
       "1                                       162   \n",
       "\n",
       "  Beach Clean Up_Number of Government Representatives  \\\n",
       "0                                                120    \n",
       "1                                                260    \n",
       "\n",
       "  Beach Clean Up_Number Local group volunteers  \\\n",
       "0                                          299   \n",
       "1                                          473   \n",
       "\n",
       "  Beach Clean Up_Number of Academic Institutions  \\\n",
       "0                                              2   \n",
       "1                                              5   \n",
       "\n",
       "  Beach Clean Up_Number of Residential Societies  \\\n",
       "0                                              1   \n",
       "1                                              2   \n",
       "\n",
       "  Waste Management_Quantity of Marine Debris Collected (Kgs)  \\\n",
       "0                                               6552           \n",
       "1                                              14940           \n",
       "\n",
       "  Waste Management_Quantity of Plastic (KGS)- Mix Plastic (Polythene, MLP, PVC, LDP)  \\\n",
       "0                                             4258.8                                   \n",
       "1                                               9711                                   \n",
       "\n",
       "  Waste Management_Quantity of Cloth (KGS)  \\\n",
       "0                                    982.8   \n",
       "1                                     2241   \n",
       "\n",
       "  Waste Management_Quantity of Wood, Shoes, Bags and other materials (KGS)  \\\n",
       "0                                             1310.4                         \n",
       "1                                               2988                         \n",
       "\n",
       "         location  \n",
       "0  Erangal, Malad  \n",
       "1  Erangal, Malad  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Erangal, Malad\"\n",
    "process_df_with_combined_headers(all_sheets[name], name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "pvq6nquj4sl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all location tabs with combined headers:\n",
      "============================================================\n",
      "\n",
      " 1. Processing: Dadar\n",
      "    Original shape: (11, 60)\n",
      "    Processed shape: (9, 51)\n",
      "    Columns: 51 (50 data + 1 location)\n",
      "\n",
      " 2. Processing: Cuff Parade\n",
      "    Original shape: (5, 16)\n",
      "    Processed shape: (1, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      " 3. Processing: Chimbai Beach, Bandra\n",
      "    Original shape: (5, 16)\n",
      "    Processed shape: (2, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      " 4. Processing: Worli Fort, Worli\n",
      "    Original shape: (5, 18)\n",
      "    Processed shape: (3, 18)\n",
      "    Columns: 18 (17 data + 1 location)\n",
      "\n",
      " 5. Processing: Madh, Malad\n",
      "    Original shape: (5, 16)\n",
      "    Processed shape: (2, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      " 6. Processing: Erangal, Malad\n",
      "    Original shape: (5, 16)\n",
      "    Processed shape: (2, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      " 7. Processing: Gorai, Bhayander\n",
      "    Original shape: (4, 16)\n",
      "    Processed shape: (1, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      " 8. Processing: Prabhadevi Beach\n",
      "    Original shape: (8, 16)\n",
      "    Processed shape: (4, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      " 9. Processing: Silver Beach\n",
      "    Original shape: (4, 15)\n",
      "    Processed shape: (2, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      "10. Processing: Juhu Koliwada, Juhu\n",
      "    Original shape: (10, 16)\n",
      "    Processed shape: (8, 16)\n",
      "    Columns: 16 (15 data + 1 location)\n",
      "\n",
      "============================================================\n",
      "✅ Successfully processed: 10/10 location tabs\n",
      "\n",
      "Column comparison across locations:\n",
      "\n",
      "  Dadar: 50 columns\n",
      "    • Beach Name_Dadar Beach (Behind Kirti College)\n",
      "    • Beach Clean Up_Number of Beach Clean Ups\n",
      "    • Beach Clean Up_Total Number of Participants\n",
      "    • Beach Clean Up_Number of Beach Warrior Volunteers\n",
      "    • Beach Clean Up_Number of Student Participants \n",
      "    ... and 45 more\n",
      "\n",
      "  Cuff Parade: 15 columns\n",
      "    • Beach Name_Cuff Parade- Machimarnagar Beach\n",
      "    • Beach Clean Up_Number of Beach Clean Ups\n",
      "    • Beach Clean Up_Total Number of Participants\n",
      "    • Beach Clean Up_Number of Beach Warrior Volunteers\n",
      "    • Beach Clean Up_Number of Student Participants \n",
      "    ... and 10 more\n",
      "\n",
      "  Chimbai Beach, Bandra: 15 columns\n",
      "    • Beach Name_Chimbai Beach, Bandra\n",
      "    • Beach Clean Up_Number of Beach Clean Ups\n",
      "    • Beach Clean Up_Total Number of Participants\n",
      "    • Beach Clean Up_Number of Beach Warrior Volunteers\n",
      "    • Beach Clean Up_Number of Student Participants \n",
      "    ... and 10 more\n",
      "\n",
      "Total unique columns across all locations: 52\n"
     ]
    }
   ],
   "source": [
    "# Process all location tabs with the new function\n",
    "print(\"Processing all location tabs with combined headers:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get all location tabs (exclude Sheet1)\n",
    "location_tabs = [name for name in all_sheets.keys() if name != 'Sheet1']\n",
    "processed_dataframes = []\n",
    "\n",
    "for i, location_name in enumerate(location_tabs):\n",
    "    print(f\"\\n{i+1:2d}. Processing: {location_name}\")\n",
    "    df = all_sheets[location_name]\n",
    "    print(f\"    Original shape: {df.shape}\")\n",
    "    \n",
    "    try:\n",
    "        processed_df = process_df_with_combined_headers(df, location_name)\n",
    "        \n",
    "        if not processed_df.empty:\n",
    "            print(f\"    Processed shape: {processed_df.shape}\")\n",
    "            print(f\"    Columns: {len(processed_df.columns)} ({len(processed_df.columns)-1} data + 1 location)\")\n",
    "            processed_dataframes.append(processed_df)\n",
    "        else:\n",
    "            print(f\"    ⚠️  WARNING: No data after processing\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ ERROR processing {location_name}: {str(e)}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"✅ Successfully processed: {len(processed_dataframes)}/{len(location_tabs)} location tabs\")\n",
    "\n",
    "# Show a sample of columns from different locations\n",
    "if processed_dataframes:\n",
    "    print(f\"\\nColumn comparison across locations:\")\n",
    "    all_columns = set()\n",
    "    for df in processed_dataframes[:3]:  # Show first 3 for brevity\n",
    "        location = df['location'].iloc[0]\n",
    "        cols = [col for col in df.columns if col != 'location']\n",
    "        all_columns.update(cols)\n",
    "        print(f\"\\n  {location}: {len(cols)} columns\")\n",
    "        for col in cols[:5]:  # Show first 5 columns\n",
    "            print(f\"    • {col}\")\n",
    "        if len(cols) > 5:\n",
    "            print(f\"    ... and {len(cols)-5} more\")\n",
    "    \n",
    "    print(f\"\\nTotal unique columns across all locations: {len(all_columns)}\")\n",
    "\n",
    "processed_dataframes[0] = processed_dataframes[0].drop('Overall Awareness Impact_', axis=1)\n",
    "for idx, _ in enumerate(processed_dataframes):\n",
    "    processed_dataframes[idx].columns = [\"Period\", *processed_dataframes[idx].columns[1:]]\n",
    "    processed_dataframes[idx] = clean_columns(processed_dataframes[idx])\n",
    "    processed_dataframes[idx] = processed_dataframes[idx].rename({\"Period\":'Year Period'}, axis=1)\n",
    "    processed_dataframes[idx]['Year Period'] = clean_period_year(processed_dataframes[idx]['Year Period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1oz6bz2ywwl",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unique_columns(columns):\n",
    "    \"\"\"Make duplicate column names unique by appending suffixes.\"\"\"\n",
    "    seen = {}\n",
    "    new_cols = []\n",
    "    for col in columns:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_cols.append(f\"{col}_{seen[col]}\")  # add suffix\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_cols.append(col)\n",
    "    return new_cols\n",
    "\n",
    "all_cleaned = []\n",
    "\n",
    "for df in processed_dataframes:\n",
    "    name = df.location.unique()[0]\n",
    "    temp = df.copy()\n",
    "\n",
    "    # Fix duplicate column names\n",
    "    temp.columns = make_unique_columns(temp.columns)\n",
    "\n",
    "    # Add sheet name column\n",
    "    temp[\"location\"] = name\n",
    "\n",
    "    all_cleaned.append(temp)\n",
    "\n",
    "# Concatenate vertically, missing cols get NaN\n",
    "final_df = pd.concat(all_cleaned, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "9af842eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../final_dataframe.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vecv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
